---
layout: post
title: docker에서 PC 그래픽과 연결해 tensorflow-gpu 실행하기
date: 2018-08-25 10:00:00 pm
permalink: posts/40
description: nvidia-docker를 활용하여 docker container에서 PC의 그래픽카드로 tensorflow-gpu를 실행한다.
img: thumbnail/docker.png 
categories: [Tech, Linux]
tags: [Docker, Nvidia-docker, Tensorflow] 
---

> nvidia-docker를 활용하여 docker container에서 PC의 그래픽카드로 tensorflow-gpu를 실행한다.

#### nvidia 그래픽카드가 설치된 PC라면 docker container에서 그래픽카드를 활용할 수 있다.

이 기능을 제공하는 것이 바로 `nvidia-docker`이다. 

nvidia-docker 설치방법은 아래 블로그에 친절하게 설명되어 있어서 그대로 따라하면 된다.

nvidia-docker2를 설치하기 위해서는 기존에 nvidia-docker를 사용했다면 삭제하고 진행한다.

#### [nvidia-docker2 설치 블로그](http://haanjack.github.io/docker/2017/12/01/nvidia-docker-ngc.html){:target="_blank"}

참고 : 위 블로그는 16.04 버전이라서 18.04에서 nvidia-docker2 repository 추가 설정할 때는 아래처럼 입력해야 한다.

```
curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | \
  sudo apt-key add -
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | \
  sudo tee /etc/apt/sources.list.d/nvidia-docker.list
```

그래픽 드라이버가 제대로 연결되어 있는지 확인하려면, 아래 명령을 사용한다.

tag명에는 설치된 그래픽 드라이버와 호환이 되는 cuda버전을 활용해야 한다. [tensorflow 설치글 참고](https://yahwang.github.io/posts/37){:target="_blank"}

#### [nvidia/cuda tag 목록](https://hub.docker.com/r/nvidia/cuda/tags/){:target="_blank"}

``` python
# nvidia/cuda는 cuda와 cudnn이 설치된 docker image이다.
sudo docker run --runtime=nvidia --rm -it nvidia/cuda:tag명 nvidia-smi
```

### unknown runtime specified nvidia 오류 해결

명령을 실행할 때, response from daemon : unknown runtime specified nvidia이라는 오류가 생길 수 있다.

![nvidia-docker1]({{site.baseurl}}/assets/img/tech/nvidia_docker1.png)

nvidia-docker는 nvidia-container-runtime을 사용해야 그래픽드라이버를 container에 연결할 수 있다.

이 오류는 이미 설치된 runtime의 경로를 설정하면 해결할 수 있다.

``` python
sudo cat /etc/docker/daemon.json # 경로 설정파일 확인
{ PATH 수정 }
sudo pkill -SIGHUP dockerd # 수정한 path를 docker에 적용하기 위함
```

![nvidia-docker2]({{site.baseurl}}/assets/img/tech/nvidia_docker2.png)

nano나 vim과 같은 편집기를 활용하여 path를  `/usr/bin/nvidia-container-runtime`으로 수정하면 된다.

![nvidia-docker3]({{site.baseurl}}/assets/img/tech/nvidia_docker3.png)

nvidia-smi가 제대로 실행되면 연결이 되는 것이다.

#### 항상 container를 생성할 때 `--runtime=nvidia`를 입력해야 그래픽 드라이버와 연결할 수 있다.

### tensorflow libcuda.so.1 오류 해결

nvidia/cuda는 tensorflow를 실행하기까지 많은 작업을 해야한다. tensorflow docker image를 활용하면 tensorflow버전이 설치된 container를 바로 만들 수 있다.

#### [tensorflow docker image](https://hub.docker.com/r/tensorflow/tensorflow/){:target="_blank"}

import tensorflow를 실행하면 ImportError: libcuda.so.1: cannot open shared object file 오류가 생길 수 있다.

![nvidia-docker4]({{site.baseurl}}/assets/img/tech/nvidia_docker4.png)

container에서 다음 명령을 실행하면 해결된다.

``` python
# libcuda.so를 libcuda.so.1 파일명으로 바로가기를 만들어서 이어준다.
ln -s /usr/local/cuda/lib64/stubs/libcuda.so /usr/local/cuda/lib64/stubs/libcuda.so.1
export LD_LIBRARY_PATH=/usr/local/cuda/lib64/stubs/:$LD_LIBRARY_PATH
```

다음 명령어로 tensorflow에서 GPU가 연결된 것을 확인할 수 있다.

``` python
from tensorflow.python.client import device_lib
device_lib.list_local_devices() # CPU, GPU를 모두 포함한 사용 가능 device 확인
```

`References` : 

* [tensorflow 실행 오류 관련](https://github.com/tensorflow/tensorflow/issues/10776){:target="_blank"}

